{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aea2a524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e497d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = r\"\"\"\n",
    "A transformer is a deep learning model that adopts the\n",
    "mechanism of attention, differentially weighing the\n",
    "significance of each part of the input data. It is used\n",
    "primarily in the field of natural language processing\n",
    "(NLP) and in computer vision (CV).\n",
    "\n",
    "Like recurrent neural networks (RNNs), transformers are \n",
    "designed to handle sequential input data, such as natural \n",
    "language, for tasks such as translation and text \n",
    "summarization. However, unlike RNNs, transformers do not\n",
    "necessarily process the data in order. Rather, the \n",
    "attention mechanism provides context for any position in \n",
    "the input sequence. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f685385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a6cb2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question: \n",
      "How do transformers work?\n"
     ]
    }
   ],
   "source": [
    "question = \"How do transformers work?\"\n",
    "print(\"The question: \")\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6b198e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(question, corpus, add_special_tokens=True, return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "outputs = model(**inputs)\n",
    "\n",
    "ans_start_scores = outputs.start_logits\n",
    "ans_end_scores = outputs.end_logits\n",
    "\n",
    "ans_start = torch.argmax(ans_start_scores)\n",
    "ans_end = torch.argmax(ans_end_scores) + 1\n",
    "\n",
    "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[ans_start:ans_end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7152a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question:\n",
      "-------------------------\n",
      "How do transformers work?\n",
      "\n",
      "The answer:\n",
      "-------------------------\n",
      "deep learning model that adopts the mechanism of attention, differentially weighing the significance of each part of the input data\n"
     ]
    }
   ],
   "source": [
    "print(f\"The question:\\n-------------------------\\n{question}\\n\")\n",
    "print(f\"The answer:\\n-------------------------\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6852e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
